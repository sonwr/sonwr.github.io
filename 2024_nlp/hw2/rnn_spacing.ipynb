{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CwxKv7Np5qMj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713410154641,"user_tz":-540,"elapsed":34517,"user":{"displayName":"Wooram Son","userId":"00243227405737702316"}},"outputId":"69c0e47f-42ec-490d-f266-0b15412cdf94"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"aY7_UjO06Emi","executionInfo":{"status":"ok","timestamp":1713410400819,"user_tz":-540,"elapsed":516,"user":{"displayName":"Wooram Son","userId":"00243227405737702316"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score\n","\n","class SpacingRNN(nn.Module):\n","    def __init__(self, config):\n","        super(SpacingRNN, self).__init__()\n","        self.embedding = nn.Embedding(num_embeddings=config['eumjeol_vocab_size'], embedding_dim=config['embedding_size'], padding_idx=0)\n","        self.dropout = nn.Dropout(config['dropout'])\n","        # 다층 LSTM 적용\n","        self.lstm = nn.LSTM(input_size=config['embedding_size'],\n","                            hidden_size=config['hidden_size'],\n","                            num_layers=config['num_layers'],  # 층 수 추가\n","                            batch_first=True,\n","                            bidirectional=True)\n","        self.linear = nn.Linear(in_features=config['hidden_size'] * 2, out_features=config['number_of_labels'])\n","\n","    def forward(self, inputs):\n","        x = self.embedding(inputs)\n","        x = self.dropout(x)\n","        x, _ = self.lstm(x)\n","        x = self.dropout(x)\n","        x = self.linear(x)\n","        return x"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"unh9In2q6OQK","executionInfo":{"status":"ok","timestamp":1713410408220,"user_tz":-540,"elapsed":372,"user":{"displayName":"Wooram Son","userId":"00243227405737702316"}}},"source":["\n","def read_datas(file_path):\n","    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n","        lines = inFile.readlines()\n","    datas = []\n","    for line in lines:\n","        pieces = line.strip().split(\"\\t\")\n","        eumjeol_sequence, label_sequence = pieces[0].split(), pieces[1].split()\n","        datas.append((eumjeol_sequence, label_sequence))\n","    return datas\n","\n","def read_vocab_data(eumjeol_vocab_data_path):\n","    label2idx, idx2label = {\"<PAD>\":0, \"B\":1, \"I\":2}, {0:\"<PAD>\", 1:\"B\", 2:\"I\"}\n","    eumjeol2idx, idx2eumjeol = {}, {}\n","    with open(eumjeol_vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n","        lines = inFile.readlines()\n","    for line in lines:\n","        eumjeol = line.strip()\n","        if eumjeol not in eumjeol2idx:\n","            eumjeol2idx[eumjeol] = len(eumjeol2idx)\n","            idx2eumjeol[eumjeol2idx[eumjeol]] = eumjeol\n","    return eumjeol2idx, idx2eumjeol, label2idx, idx2label\n","\n","def load_dataset(config, data_path):\n","    datas = read_datas(data_path)\n","    eumjeol2idx, idx2eumjeol, label2idx, idx2label = read_vocab_data(config[\"eumjeol_vocab\"])\n","    eumjeol_features, eumjeol_feature_lengths, label_features = [], [], []\n","\n","    for eumjeol_sequence, label_sequence in datas:\n","        eumjeol_feature = [eumjeol2idx[eumjeol] for eumjeol in eumjeol_sequence]\n","        label_feature = [label2idx[label] for label in label_sequence]\n","        eumjeol_feature_length = len(eumjeol_feature)\n","        eumjeol_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","        label_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","        eumjeol_features.append(eumjeol_feature)\n","        eumjeol_feature_lengths.append(eumjeol_feature_length)\n","        label_features.append(label_feature)\n","\n","    return torch.tensor(eumjeol_features, dtype=torch.long), torch.tensor(eumjeol_feature_lengths, dtype=torch.long), torch.tensor(label_features, dtype=torch.long), eumjeol2idx, idx2eumjeol, label2idx, idx2label\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBfpm6Ts6Reg","executionInfo":{"status":"ok","timestamp":1713410410615,"user_tz":-540,"elapsed":370,"user":{"displayName":"Wooram Son","userId":"00243227405737702316"}}},"source":["\n","def train(config):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = SpacingRNN(config).to(device)\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config, config[\"train_data\"])\n","    train_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    for epoch in range(config[\"epoch\"]):\n","        model.train()\n","        costs = []\n","\n","        for step, batch in enumerate(train_dataloader):\n","            optimizer.zero_grad()\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n","            hypothesis = model(inputs)\n","            cost = loss_func(hypothesis.view(-1, config['number_of_labels']), labels.view(-1))\n","            cost.backward()\n","            optimizer.step()\n","            costs.append(cost.item())\n","\n","        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], f\"epoch_{epoch + 1}.pt\"))\n","        print(f\"Epoch {epoch + 1}: Average Cost = {np.mean(costs)}\")\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-A9SurF6UgG","executionInfo":{"status":"ok","timestamp":1713410412412,"user_tz":-540,"elapsed":2,"user":{"displayName":"Wooram Son","userId":"00243227405737702316"}}},"source":["\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","def make_sentence(inputs, predicts, labels, idx2eumjeol, idx2label):\n","    predict_sentence, correct_sentence = \"\", \"\"\n","    for index in range(len(inputs)):\n","        eumjeol = idx2eumjeol[inputs[index]]\n","        correct_label = idx2label[labels[index]]\n","        predict_label = idx2label[predicts[index]]\n","        if (index == 0):\n","            predict_sentence += eumjeol\n","            correct_sentence += eumjeol\n","            continue\n","        if (predict_label == \"B\"):\n","            predict_sentence += \" \"\n","        predict_sentence += eumjeol\n","        if (correct_label == \"B\"):\n","            correct_sentence += \" \"\n","        correct_sentence += eumjeol\n","    return predict_sentence, correct_sentence\n","\n","def test(config):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config, config[\"test_data\"])\n","    test_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=1)\n","    model = SpacingRNN(config).to(device)\n","    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"]), map_location=device))\n","    total_hypothesis, total_labels = [], []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n","        hypothesis = model(inputs)\n","        hypothesis = torch.argmax(hypothesis, dim=-1)\n","        input_length = tensor2list(input_lengths[0])\n","        input = tensor2list(inputs[0])[:input_length]\n","        label = tensor2list(labels[0])[:input_length]\n","        hypothesis = tensor2list(hypothesis[0])[:input_length]\n","        total_hypothesis += hypothesis\n","        total_labels += label\n","        if (step < 10): # 처음 10개만 화면에 예시로 출력\n","            predict_sentence, correct_sentence = make_sentence(input, hypothesis, label, idx2eumjeol, idx2label)\n","            print(\"정답 : \" + correct_sentence)\n","            print(\"출력 : \" + predict_sentence)\n","            print()\n","    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kj-JT2466U9u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccf11f9e-fe7b-486e-caec-8cd9c2dcdd5d"},"source":["if(__name__==\"__main__\"):\n","    root_dir = \"/gdrive/My Drive/colab\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\n","        \"mode\": \"train\",\n","\n","        \"inter_layer_dropout\": 0.3,  # LSTM 층 사이의 드롭아웃\n","        \"num_layers\": 5,  # LSTM 층 수\n","        \"dropout\": 0.3, # 드롭아웃 레이어: 과적합을 방지하기 위해 특정 비율(config[\"dropout\"])로 뉴런의 출력을 임의로 0으로 설정\n","        \"hidden_size\": 64,  # RNN 히든 사이즈: LSTM 셀 또는 RNN 셀의 히든 상태의 차원 수를 설정. 네트워크의 메모리 용량을 결정\n","        \"batch_size\": 64,\n","        \"epoch\": 15,\n","        \"number_of_labels\": 3,  # 분류할 라벨의 개수: 모델 출력층에서 예측할 라벨(클래스)의 개수\n","\n","        \"eumjeol_vocab_size\": 2000,  # 전체 음절 개수: 모델이 인식하고 처리할 수 있는 고유 음절의 총 수를 정의\n","        \"embedding_size\": 128,  # Embedding Size: 고차원 벡터를 훨씬 낮은 차원의 밀집 벡터(dense vector)로 변환\n","        \"max_length\": 920,  # Maximum length of sentences\n","\n","        \"train_data\": os.path.join(root_dir, \"train.txt\"),\n","        \"test_data\": os.path.join(root_dir, \"test.txt\"),\n","        \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n","        \"output_dir\": output_dir,\n","        \"model_name\":\"epoch_{0:d}.pt\".format(5),\n","      }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Average Cost = 0.6648911396159402\n","Epoch 2: Average Cost = 0.5083800026133091\n","Epoch 3: Average Cost = 0.23176081195662293\n","Epoch 4: Average Cost = 0.1890881883947155\n","Epoch 5: Average Cost = 0.16790042195139052\n","Epoch 6: Average Cost = 0.15346075943376444\n"]}]},{"cell_type":"code","metadata":{"id":"1BA8wtxg6Y9R"},"source":[],"execution_count":null,"outputs":[]}]}